DESCRIPTION:
------------

###########################
##  GENERAL DESCRIPTION  ##
###########################

I have used 2 data sets for this Assignment , one was used for clustering/Community Detection , while the other
was used for classification of sentiment.

They are as follows:
--------------------

1) Community Detection of Ellon Musk's Followers and their followers .

2) Classification of Sentiment of tweets related to Donald Trump.

Classification of Sentiment of Tweets related to Donald Trump:
--------------------------------------------------------------
So i collected around 400 tweets first related to the term "Trump" then i manually annotated them to use it as
my training set for my support vector machine classifier, next i collected 1000 more tweets using the same methods
in collect.py and used this as my testing set. Then in classify.py i read these saved tweets from the .csv file and
my manually annotated training set then create my Train and Test csr Matrices. Here i first remove the stopwords
using the nltk stopwords corpus , after which the documents are vectorized to create my csr matrices. After this
I use these matrices in my Support Vector Machine to classify them as either Positive Sentiment (Class Label : 1) or
Negative Sentiment (Class Label : 0).

Clustering of Followers of Ellon Musk:
--------------------------------------
I collected 300 followers of Ellon Musk, then i collected 300 more followers for each of the original 300 , to try and
identify the communities or the similarity between the people who follow Ellon Musk. After this i read the saved .json
file generated by collect.py in my cluster.py after which i generate a graph using the networkx library .

Graph is represented in this way:

1) Node : Each node is represented as a user , using his user_id

2) Edge : This represents the relationship between each Node , here i define the relationship to be    
  -> if A follows B then edge AB exists  
  -> if B follows A then still edge AB exists  
  I have used a Undirected Graph for this.

After the graph Generation i save it before clustering as Graph.png, after which i cluster this graph using girvan_newman
graph clustering algorithm. After the clustering i save the cluster details as well as plot the graph with clusters, where
each color of a node in my graph represents a cluster.

***********************************************************************************************************************

###########################
##  HOW TO EXECUTE CODE  ##
###########################

1) Run collect.py first before any of the other files to collect the data to classify and cluster.
   cmd: python collect.py

2) Then you can either run cluster.py or classify.py.
   cmd: python cluster.py
   cmd: python classify.py

3) Now after running all the 3 shown above , run summarize.py
   cmd: python summarize.py

4) To view the 'summary.txt' check the Summarize_Folder folder

5) To view the unclustered graph 'Graph.png' and clustered graph 'Clustered_Graph.png' check the Cluster_Folder folder.

6) To view the clusters of twitter user id's check the cluster.txt file in the Cluster_Folder folder.

***********************************************************************************************************************

###########################
##       ANALYSIS        ##
###########################

Clustering :
------------
Here i noticed the problem with clustering the followers of Ellon musk and each Follower's followers was that
when i plotted this data as a graph there were already pre-existing clusters/communities but when i started collecting
more data i noticed that 4 individual cluster groups ended up being a part of a larger cluster group and this continued
when i started to collect more and more data. I noticed that through a single node large number of communites get
interconnected hence if that node / user starts a trend that effect can ripple/ spread through to these other communites
through that one person. Hence it becomes easier for people who do marketing to analyze which customer's to target in
this way. If more data about each user was available then we could categorize each cluster's sex, age-group and occupation
they do then we could get more insights on what kind of people actually follow Ellon Musk and what kind of people follow
the followers of Ellon Musk.

Classification:
---------------
Here i noticed that removing urls before vectorizing gave me a higher accuracy for sentiment classification as well
as using stopwords. But the main problem here was the examples for positive class were very few in number compared to my
negative class examples, even after 4 days of continous streaming and checking, another problem that occured was instead
of Donald Trump alot of tweets were also about his wife and children, hence i had to manually filter them before annotation.
But in the end i think due to lack of enough positive class examples my classifier might not perform satisfactorily when
it comes to classifying a positive tweet about "Trump" hence next time i need to pay more attention to the quality of tweets
i get and not just the amount. Another problem that occured was since this were all tweets alot of words were abbreviated
or not of the right form hence they might confuse the classifier, hence a dictionary/ spelling checker would help us more
in this kind of scenario. But overall i think my classifier works well and you could actually see that the sentiment for
Trump here is more negative than positive on twitter even though he won the majority of the votes, i think this could be due
to the fact that more data was needed and that a lot of trump's followers might not actually be on twitter.

************************************************************************************************************************

IMPORTANT NOTE:
--------------
Due to twitter api's rate limmiting the process of collecting the followers takes a very long time,
hence if you do not want to wait that long then you need to change :

In collector.py , in main() method  line 230:
--> change users_count parameter in the method followers_map() to a lower value :
    if you put users_count =  x
    then you get back around x^2 id's in total.

Also in Graph clustering in cluster.py generating the clustered graph takes quite a while with large data and this
just increases for large cluster number , i have given the no of clusters to form as 7 as a parameter to my method
and this takes alot of time . When testing you can change this to a smaller number and check.

change line 239 in cluster.py :
--> in the method cluster_graph() change 'k' to a smaller value for faster runtime.

************************************************************************************************************************

REQUIREMENTS:
-------------
For my code to work these are the libraries that are required.  
1) SKlearn  
2) OS  
3) TwitterApi  
4) twitter                      (Streaming api : install using --> pip install twitter)  
5) Nltk stopword corpus         (install using --> nltk download then pick the stopword corpus and install)  
6) Faker                        (install using --> pip install faker)  
7) Networkx  
8) Itertools  
9) Matplotlib

************************************************************************************************************************
